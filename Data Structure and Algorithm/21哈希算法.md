# 21~22 | 哈希算法

### 一、哈希算法定义

将任意长度的二进制值串映射为**固定长度**的二进制值串，这个**映射规则**就是哈希算法。通过原始数据映射之后得到的二进制串就是哈希值。

### 二、哈希算法设计要求

- **单方向性** 不能利用哈希值反向推导出原始数据
- **高数据敏感性** 即使原始数据只被修改了一比特，最后得到的哈希值也相差甚远
- **小散列冲突概率** 对不同的原始数据，哈希值相同的概率要非常小
- **高执行效率** 针对较长的文本，能快速计算出哈希值

### 三、哈希算法常见的应用

常见的i七个应用：安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。

#### 1. 安全加密

最常用于加密的哈希算法

MD5：MD5 Message-Digest Algorithm，MD5消息摘要算法
SHA：Secure Hash Algorithm，安全散列算法
DES：Data Encryption Standard，数据加密标准
AES：Advanced Encryption Standard，高级加密标准

有两点格外重要：第一点是很难根据哈希值反向推导出原始数据，第二点是散列冲突的概率要很小。

没有绝对安全的加密：越复杂、越难破解的加密算法，需要的计算时间也越长。

在实际的开发过程中，需要权衡**破解难度**和**计算时间**，来决定使用哪种加密算法。

#### 2. 唯一标识

例子：如何在图库中搜索一张图是否存在？

* 不能单纯用图片的元信息（比如图片名称）来对比，因为可能存在图片名称相同但内容不同，或者名称不同但内容相同的情况。
* 任何文件都可以表示成二进制码串，所以拿要查找图片的二进制码与图库中所有图片的二进制码串一一对比，如果相同，那么图库中存在该图片。然而图片转换成的二进制码串在对比时非常耗时。
* 可以给每张图片取唯一标识。例如分别取每张图片二进制码串的开始、中间和最后的100个字节，合成300字节，通过哈希算法得到一个哈希字符串，用这个字符串作为图片的唯一标识。通过这个唯一标识判断图片是否在图库中，减少工作量。
* 为了提高效率，可将每张图片的唯一标识和其在图库中的路径信息存储于散列表中，寻找图片时，通过哈希算法获得该图片的唯一标识，然后在散列表中查找该唯一标识是否存在。如果存在，通过散列表中文件路径获取图库中的图片，跟寻找的图片做全量对比，看是否完全一样。倘若一样，说明已存在；不一样说明两张图片尽管唯一标识相同，但并非相同图片。

#### 3. 数据校验

BT下载的原理是基于P2P协议，从多个机器上并行下载一个2GB的电影，这个电影文件可能会被分割成很多文件块（比如可以分成100块，每块大约20MB）。所有文件块都下载好了以后，再组装成一个完整的电影文件。

如何校验文件块的安全、正确和完整性呢？

其中一种思路是：通过哈希算法，对100个文件块分别取哈希值，并保存于种子文件中。 当文件块下载完成以后，通过相同的哈希算法对下载好的文件块逐一求哈希值，跟种子文件中保存的哈希值对比。如果不同，说明文件块不完整或是被篡改，需要重新从其他宿主机器上下载这个文件块。

#### 4. 散列函数

散列函数也是哈希算法的一种应用，但是对散列算法冲突的要求很低。即使出现个别散列冲突，只要不是过于严重，都可以通过开放寻址或者链表法解决。

散列函数也不关心能否反向解密通过散列算法得到的值。散列函数中用到的散列算法比较关注散列后的值是否能平均分布，执行效率是否快速。因此，散列函数所用散列算法一般都比较简单，追求效率。

#### 5. 负载均衡

负载均衡算法有很多，比如轮询、随机、加权轮询等。如何实现一个会话粘滞（session sticky）的负载均衡算法？即是说，需要在同一个客户端上，把一次会话中的所有请求都路由到同一个服务器上。

最直接的方法是维护一张映射关系表，内容是客户端IP地址/会话ID与服务器编号的映射关系。客户端每次法出请求，都要现在映射表中查找应该路由到的服务器编号，然后请求编号对应的服务器。

上述方法虽简单直观但也有弊端。如果客户端数量很多，映射表会很大。浪费内存空间。客户端下线、上线、服务器扩容、缩容都会导致映射失效，那么维护映射表的成本很大。

然而借助哈希算法可以有效解决这些弊端。通过哈希算法对客户端IP地址或者会话ID计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。

#### 6. 数据分片

eg:如何统计“搜索关键词”出现的次数？

假设有1T的日志文件，记录了**用户的搜索关键词**，怎样快速统计出每个关键词被搜索的次数？

由于搜索日志很大，没办法放到一台机器的内存当中；而且倘若只用一台机器来处理这样巨大的数据，那么处理时间会很长。

**可以先对数据进行分片，然后采用多台机器处理的方法，提高处理速度。**

具体思路：用n台机器并行处理，从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，得出的哈希值与n取模，得出被分配的机器编号。哈希值相同的搜索关键词被分配到同一个机器上，每台机器会分别计算关键词出现的次数，最后合并起来就是最终结果。

eg:在唯一标识中已经提出方法来判断 一张图片是否存在于图库中，但是如果图库中有1亿张图片，那么单台机器构建散列表就不太能行得通了。机器内存有限，而一亿张图片构建散列表显然远远超过了单台机器的内存上限。

同样像上一个例子那般先对数据进行分片，多机处理。利用图片的唯一标识与机器台数n求余取模，分配到机器编号，将图片唯一标识和图片路径发往对应的机器构建散列表。利用图片唯一标识与机器个数n求余取模去对应机器的散列表中查找图片。

估算需要机器数n：图片唯一标识为用MD5计算出的哈希值，长度128比特，16字节；文件路径长度上限为256字节，假设平均长度128字节；如果用链表法解决冲突，还需要存储8字节的指针。散列表当中每个数据单元占用152字节。

假设每台机器内存为2GB，散列表装载因子0.75，那么大约需要十几台（10^8/(2GB*0.75/152)）机器。在工程中，这种估算很重要，能让我们事先对需要投入的资源、资金有个初步的了解，更好地评估解决方案的可行性。

总结：针对这类处理大量数据的问题，都可以采用多机分布式处理。借助这种分片思路，可以突破单机内存、CPU等资源的限制。

#### 7. 分布式存储

互联网面对海量的数据和用户，为了提高数据的读取、写入能力，一般采用分布式的方式来存储数据，比如分布式缓存，将数据分布在多台机器上面。

为了能够不用在新加入数据后做大量的数据搬移，运用**一致性哈希算法**十分重要。基本思想：假设有K个机器，数据的哈希值范围是[0,MAX]。将范围划分成m个小区间（m远大于K），每个机器负责m/K个小区间。当有新机器加入时，将某几个小区间的数据，从原来的机器搬移至新的机器中。

一致性哈希算法详细：[漫画算法：什么是一致性哈希？](https://www.sohu.com/a/158141377_479559)

### 四、如何防止数据库中的用户信息被脱库？

2011年CSDN网站被黑客攻击，超过600万用户的注册邮箱和密码明文被泄露。如何存储用户密码这类重要的数据？

可以通过哈希算法，对用户密码加密之后再存储。选择相对安全的加密算法，例如SHA。然而很多用户习惯将密码设置成很简单的数字组合，例如1234356，黑客很容易猜中密码。

所以需要维护一个常用密码的字典表，将字典表中的明文密码用哈希算法计算哈希值，与脱库后的密文对比。如果相同，**基本**可以认为加密之后的密码就是字典中的密码。

针对字典攻击，可以引入一个盐（salt），与用户的明文密码组合，增加密码复杂度。组合之后的字符串做哈希算法加密，进一步增加破解的难度。加盐方式有很多种，头部、中间部分、尾部都可以加盐，甚至可以是随机的。

安全和攻击是一种博弈关系，不存在绝对的安全，所有的安全措施，只是增加攻击的成本而已。



